{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing 911 Calls and \n",
    "[Click here for live site!](https://m-sender.github.io/ServiceLearning)\n",
    "\n",
    "# **Max Sender and Sam Traylor**\n",
    "\n",
    "### Data set link: [Calls for service 2021](https://data.nola.gov/Public-Safety-and-Preparedness/Calls-for-Service-2021/3pha-hum9)\n",
    "\n",
    "What this data set is a collection of 9-1-1 calls in 2021 in the New Orleans Area. This set contains basic things such as the type of incident, where it was, the police department, and timing, and more.\n",
    "\n",
    "## Questions\n",
    "\n",
    "#### We find this data set to be very insightful and can answer a lot of different questions. One route we can take is analyzing the data set to focusing on emergency response and answer questions regarding that. If this route is chosen, another dataset that could be of use is [Police Zone Information](https://data.nola.gov/dataset/Police-Zones/fngt-zkj9). This lets us expand our questions to answer more zone and area specific questions. Questions that we can answer going this route are:\n",
    "\n",
    "*   Average response time by incident?\n",
    "\n",
    "*   Average response time by zone/area?\n",
    "\n",
    "*   Average response time by incident in specific areas?\n",
    "\n",
    "#### Another route we can go with the data is focusing more on the crime aspect of the data set. This route will be more focused on answering questions about crime in specific areas instead of the emergency response.\n",
    "\n",
    "*   Most frequent crimes in specific areas?\n",
    "\n",
    "*   Based on the value counts of each type of crime in each area can we generalize patterns like violent crime happening more in one area, theft in another, etc?\n",
    "\n",
    "*   What are the most frequest crimes by time of day in conjunction with a specific area?\n",
    "\n",
    "#### There are more routes we can choose from and more questions will come to mind upon further analysis of the datasets. A combination of multiple routes will most likely render the most promising and insightful results.\n",
    "\n",
    "## Collaboration plan:\n",
    "\n",
    "We plan to collaborate via meetings over zoom, and store our data in a shared github. Any particular challenges that have to be solved in a pair-programming setting will be dealt with using live share on vscode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Calls_untidy = pd.read_csv(\"../data/Calls_for_Service_2021.csv\")\n",
    "df_zones_untidy = pd.read_csv(\"../data/Police_Zones_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Calls = df_Calls_untidy.drop(columns=['NOPD_Item','Type','InitialType','MapX','MapY','Disposition','Beat'])\n",
    "#set type to date time objects\n",
    "df_Calls = df_Calls.astype({'TimeCreate':'datetime64[ns]','TimeDispatch':'datetime64[ns]',\"TimeArrive\":'datetime64[ns]',\"TimeClosed\":'datetime64[ns]'})\n",
    "df_Calls.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Columns Explained:**\n",
    "* TypeText: Type of incident (text)\n",
    "* Priority: Priority of incident (ID)\n",
    "* InitialTypeText: Initial type of incident (text)\n",
    "* InitialPriority: Initial priority of incident (ID)\n",
    "* TimeCreate: Time of incident\n",
    "* TimeDispatch: Time of dispatch\n",
    "* TimeArrive: Time of arrival\n",
    "* TimeClose: Time of closure\n",
    "* DispositionText: Disposition of incident (text)\n",
    "* SelfInitiated: Self-initiated (Y or N)\n",
    "* BLOCK_ADDRESS: Block address of incident\n",
    "* Zip: Zip code of incident\n",
    "* PoliceDistrict: Police district of incident (ID)\n",
    "* Location: Location of incident (ID)\n",
    "Each entry in the dataset in a unique call to 911 dispatch with relevant information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones_untidy.head(5)\n",
    "df_zones = df_zones_untidy.set_index(\"OBJECTID\")\n",
    "df_zones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the_geom: Polygon defining the zone in question\n",
    "* OBJECTID: ??\n",
    "* Zone: The police zone\n",
    "* District: The district within the zone\n",
    "* Shape_Length: The perimeter of the zone\n",
    "* Share_Area: The the area inside of the zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here lets make tables and stuff by grouping by zones, type of incidents, and other things that answer our question\n",
    "#we should be good after this and then in our plan we can say we will be making a map of the data we find and then graphs and such of data stuff than cant be mapped\n",
    "\n",
    "#remove TypeText where the count is less than 5\n",
    "new_df = df_Calls.TypeText.value_counts()\n",
    "new_df>1200 \n",
    "#df_help = df_Calls[new_df>1200]\n",
    "\n",
    "type_by_district = df_Calls[['PoliceDistrict','TypeText']].pivot_table(index=['PoliceDistrict'],columns=['TypeText'],aggfunc=np.count_nonzero)\n",
    "df_Calls_crossTab = pd.crosstab(df_Calls['PoliceDistrict'],df_Calls['TypeText'])\n",
    "display((df_Calls_crossTab.T / df_Calls_crossTab.T.sum()).T.plot(kind='bar',stacked=True, legend=False))\n",
    "type_by_district.plot(kind='bar', stacked=True, legend=False) #need to convert to marginal distribution for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using that same response time column, we could look at the means across different areas (using the police district or zip column of this dataset)\n",
    "#Using the results of the last question, we could further specify the avergage response time across incident type column values AND area column values.\n",
    "#Using zone information and response time, determine \"holes\" in the zones where response time is higher than the norm or where the area has an increase in crime due to the response times.\n",
    "#Get the value counts of each different crime for each time of day (we could categorize into several-hour windows like afternoon, evening, night, late night)\n",
    "#We could use measures of variance like the standard deviation from average response time, which would allow us to identify 'holes' wherever the response time is far higher than average.\n",
    "df_Calls[\"responseTime\"] = df_Calls.TimeArrive - df_Calls.TimeDispatch\n",
    "\n",
    "print(\"Maximum response time: \", df_Calls.responseTime.max())\n",
    "print(\"Mean response time: \", df_Calls.responseTime.mean(), \"\\n\") \n",
    "\n",
    "mean_by_zone = df_Calls.groupby([\"PoliceDistrict\"])\n",
    "for group in mean_by_zone:\n",
    "    print(\"Average response time in District\", group[0], \": \", group[1].responseTime.mean())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6d5ebbc22686cbf87e792bf78f7dd83e8c50b321b9443f473afd7acb3f9cb7d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('Capstone': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
